{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic modeling\n",
    "https://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - create an id => word mapping, aka dictionary  **gensim.corpora.Dictionary**\n",
    " - transform a document into a bag-of-word vector, using a dictionary \n",
    " - transform a stream of documents into a stream of vectors **doc2bow**\n",
    " - transform between vector streams, using topic models\n",
    " - store and save trained models, for persistency\n",
    " - use manual and semi-automated methods to evaluate quality of a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LDA\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/lda_training_tips.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data.\n",
    "\n",
    "import os\n",
    "\n",
    "# Folder containing all NIPS papers.\n",
    "data_dir = 'nipstxt/'\n",
    "\n",
    "# Folders containin individual NIPS papers.\n",
    "yrs = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "dirs = ['nips' + yr for yr in yrs]\n",
    "\n",
    "# Read all texts into a list.\n",
    "docs = []\n",
    "for yr_dir in dirs:\n",
    "    files = os.listdir(data_dir + yr_dir)\n",
    "    for filen in files:\n",
    "        # Note: ignoring characters that cause encoding errors.\n",
    "        with open(data_dir + yr_dir + '/' + filen) as fid:\n",
    "            txt = fid.read()\n",
    "        docs.append(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and vectorize the documents\n",
    "Among other things, we will:\n",
    "\n",
    "Split the documents into tokens.</br>\n",
    "<br>Lemmatize the tokens.</br>\n",
    "<br>Compute bigrams.</br>\n",
    "<br>Compute a bag-of-words representation of the data.</br>\n",
    "<br>First we tokenize the text using a regular expression tokenizer from NLTK. We remove numeric tokens and tokens that are only a single character, as they don't tend to be useful, and the dataset contains a lot of them.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    #docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    doc = ' '.join(docs[idx])\n",
    "    docs[idx] = tokenizer.tokenize(doc)  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isdigit()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token.lower() for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the WordNet lemmatizer from NLTK. A lemmatizer is preferred over a stemmer in this case because it produces more readable words. Output that is easy to read is very desirable in topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Lemmatize all words in documents.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Term Topics Methods and Document Coloring\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're setting up our corpus now. We want to show off the new get_term_topics and get_document_topics functionalities, and a good way to do so is to play around with words which might have different meanings in different context.\n",
    "\n",
    "The word bank is a good candidate here, where it can mean either the financial institution or a river bank. In the toy corpus presented, there are 11 documents, 5 river related and 6 finance related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "import numpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [['bank','river','shore','water'],\n",
    "        ['river','water','flow','fast','tree'],\n",
    "        ['bank','water','fall','flow'],\n",
    "        ['bank','bank','water','rain','river'],\n",
    "        ['river','water','mud','tree'],\n",
    "        ['money','transaction','bank','finance'],\n",
    "        ['bank','borrow','money'], \n",
    "        ['bank','finance'],\n",
    "        ['finance','money','sell','bank'],\n",
    "        ['borrow','sell'],\n",
    "        ['bank','loan','sell']]\n",
    "\n",
    "# create dictionary of mapping between word and id for documents (a list of document)\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "# create bag-of-words mapping between word and count in each document (a list of words)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (3, 1), (5, 1), (7, 1)], [(0, 2), (1, 1), (3, 1), (8, 1)], [(1, 1), (3, 1), (6, 1), (9, 1)], [(0, 1), (10, 1), (11, 1), (12, 1)], [(0, 1), (11, 1), (13, 1)], [(0, 1), (10, 1)], [(0, 1), (10, 1), (11, 1), (14, 1)], [(13, 1), (14, 1)], [(0, 1), (14, 1), (15, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "numpy.random.seed(27) # setting random seed to get the same results each time.\n",
    "model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=2, passes=23, iterations = 400, minimum_phi_value=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.184*\"water\" + 0.150*\"river\" + 0.147*\"bank\" + 0.083*\"flow\" + 0.083*\"tree\" + 0.050*\"fast\" + 0.050*\"fall\" + 0.050*\"shore\" + 0.050*\"mud\" + 0.050*\"rain\"'),\n",
       " (1,\n",
       "  u'0.214*\"bank\" + 0.134*\"money\" + 0.134*\"sell\" + 0.134*\"finance\" + 0.095*\"borrow\" + 0.057*\"transaction\" + 0.057*\"loan\" + 0.019*\"water\" + 0.019*\"river\" + 0.019*\"rain\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_term_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function get_term_topics returns the odds of that particular word belonging to a particular topic. A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.17019226)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.11727806)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('finance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.13316578), (1, 0.1992695)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('bank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_document_topics and Document Word-Topic Coloring\n",
    "<br>get_document_topics is an already existing gensim functionality which uses the inference function to get the sufficient statistics and figure out the topic distribution of the document.\n",
    "\n",
    "<br>The addition to this is the ability for us to now know the topic distribution for each word in the document. Let us test this with two different documents which have the word bank in it, one in the finance context and one in the river context.\n",
    "\n",
    "<br>The get_document_topics method returns (along with the standard document topic proprtion) the word_type followed by a list sorted with the most likely topic ids, when per_word_topics is set as true.\n",
    "\n",
    "<br>phi_values contains the phi values for each topic for that particular word, scaled by feature length. Phi is essentially the probability of that word in that document belonging to a particular topic. The next few lines should illustrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_water = ['bank','water','bank']\n",
    "bow_finance = ['bank','finance','bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.74007785), (1, 0.25992215)]\n",
      "[(0, [0, 1]), (3, [0])]\n",
      "[(0, [(0, 1.4690419), (1, 0.53095806)]), (3, [(0, 0.99194235)])]\n"
     ]
    }
   ],
   "source": [
    "bow = model.id2word.doc2bow(bow_water) # convert to bag of words format first\n",
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "\n",
    "print doc_topics\n",
    "print word_topics\n",
    "print phi_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [1, 0]), (10, [1])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bow = model.id2word.doc2bow(bow_finance) # convert to bag of words format first\n",
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_document_topics for entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.88324851), (1, 0.11675149)]\n",
      "Word topics: [(0, [0, 1]), (1, [0]), (2, [0]), (3, [0])]\n",
      "Phi values: [(0, [(0, 0.92862684), (1, 0.071373127)]), (1, [(0, 0.99784774)]), (2, [(0, 0.99170369)]), (3, [(0, 0.99827558)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.9146843), (1, 0.085315689)]\n",
      "Word topics: [(1, [0]), (3, [0]), (4, [0]), (5, [0]), (6, [0])]\n",
      "Phi values: [(1, [(0, 0.998752)]), (3, [(0, 0.99900019)]), (4, [(0, 0.99527323)]), (5, [(0, 0.9975462)]), (6, [(0, 0.99754167)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.88262689), (1, 0.11737306)]\n",
      "Word topics: [(0, [0, 1]), (3, [0]), (5, [0]), (7, [0])]\n",
      "Phi values: [(0, [(0, 0.92778981), (1, 0.072210215)]), (3, [(0, 0.99825376)]), (5, [(0, 0.99571902)]), (7, [(0, 0.99160117)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.88899761), (1, 0.11100236)]\n",
      "Word topics: [(0, [0, 1]), (1, [0]), (3, [0]), (8, [0])]\n",
      "Phi values: [(0, [(0, 1.8475267), (1, 0.15247336)]), (1, [(0, 0.99768931)]), (3, [(0, 0.99814856)]), (8, [(0, 0.99107468)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.8976118), (1, 0.10238822)]\n",
      "Word topics: [(1, [0]), (3, [0]), (6, [0]), (9, [0])]\n",
      "Phi values: [(1, [(0, 0.9984405)]), (3, [(0, 0.99875063)]), (6, [(0, 0.99692935)]), (9, [(0, 0.99397767)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.10714568), (1, 0.89285433)]\n",
      "Word topics: [(0, [1, 0]), (10, [1]), (11, [1]), (12, [1])]\n",
      "Phi values: [(0, [(0, 0.027112981), (1, 0.97288704)]), (10, [(1, 0.99823666)]), (11, [(1, 0.99825269)]), (12, [(1, 0.99495149)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.13583709), (1, 0.86416292)]\n",
      "Word topics: [(0, [1, 0]), (11, [1]), (13, [1])]\n",
      "Phi values: [(0, [(0, 0.037112422), (1, 0.96288759)]), (11, [(1, 0.997585)]), (13, [(1, 0.99635279)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.18806119), (1, 0.81193876)]\n",
      "Word topics: [(0, [1, 0]), (10, [1])]\n",
      "Phi values: [(0, [(0, 0.059980474), (1, 0.94001955)]), (10, [(1, 0.99597204)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.10637216), (1, 0.89362782)]\n",
      "Word topics: [(0, [1, 0]), (10, [1]), (11, [1]), (14, [1])]\n",
      "Phi values: [(0, [(0, 0.026640793), (1, 0.97335905)]), (10, [(1, 0.99826819)]), (11, [(1, 0.99828392)]), (14, [(1, 0.99827117)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.16921012), (1, 0.83078986)]\n",
      "Word topics: [(13, [1]), (14, [1])]\n",
      "Phi values: [(13, [(1, 0.99542695)]), (14, [(1, 0.99694854)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.13688298), (1, 0.86311704)]\n",
      "Word topics: [(0, [1, 0]), (14, [1]), (15, [1])]\n",
      "Phi values: [(0, [(0, 0.037805561), (1, 0.9621945)]), (14, [(1, 0.99752015)]), (15, [(1, 0.99280798)])]\n",
      " \n",
      "-------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_topics = model.get_document_topics(corpus, per_word_topics=True)\n",
    "\n",
    "for doc_topics, word_topics, phi_values in all_topics:\n",
    "    print('New Document \\n')\n",
    "    print 'Document topics:', doc_topics\n",
    "    print 'Word topics:', word_topics\n",
    "    print 'Phi values:', phi_values\n",
    "    print(\" \")\n",
    "    print('-------------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to store doc_topics, word_topics and phi_values for all the documents in the corpus in a variable and later access details of a particular document using its index, it can be done in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = model.get_document_topics(corpus, per_word_topics=True)\n",
    "all_topics = [(doc_topics, word_topics, word_phis) for doc_topics, word_topics, word_phis in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(0, 0.88262308), (1, 0.11737685)], [(0, [0, 1]), (3, [0]), (5, [0]), (7, [0])], [(0, [(0, 0.92778468), (1, 0.072215326)]), (3, [(0, 0.99825364)]), (5, [(0, 0.99571872)]), (7, [(0, 0.99160057)])])\n"
     ]
    }
   ],
   "source": [
    "print topics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.88325179), (1, 0.11674824)]\n",
      "Word topic: [(0, [0, 1]), (1, [0]), (2, [0]), (3, [0])]\n",
      "Phi value: [(0, [(0, 0.92863131), (1, 0.071368754)]), (1, [(0, 0.99784786)]), (2, [(0, 0.99170423)]), (3, [(0, 0.99827564)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.91467839), (1, 0.085321568)]\n",
      "Word topic: [(1, [0]), (3, [0]), (4, [0]), (5, [0]), (6, [0])]\n",
      "Phi value: [(1, [(0, 0.9987517)]), (3, [(0, 0.99899995)]), (4, [(0, 0.99527264)]), (5, [(0, 0.99754578)]), (6, [(0, 0.99754131)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.88263309), (1, 0.11736689)]\n",
      "Word topic: [(0, [0, 1]), (3, [0]), (5, [0]), (7, [0])]\n",
      "Phi value: [(0, [(0, 0.92779815), (1, 0.072201908)]), (3, [(0, 0.998254)]), (5, [(0, 0.99571955)]), (7, [(0, 0.99160224)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.8890214), (1, 0.1109786)]\n",
      "Word topic: [(0, [0, 1]), (1, [0]), (3, [0]), (8, [0])]\n",
      "Phi value: [(0, [(0, 1.8475925), (1, 0.15240757)]), (1, [(0, 0.99769038)]), (3, [(0, 0.99814945)]), (8, [(0, 0.99107885)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.89761943), (1, 0.10238061)]\n",
      "Word topic: [(1, [0]), (3, [0]), (6, [0]), (9, [0])]\n",
      "Phi value: [(1, [(0, 0.99844098)]), (3, [(0, 0.99875093)]), (6, [(0, 0.99692994)]), (9, [(0, 0.99397874)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.10714976), (1, 0.89285022)]\n",
      "Word topic: [(0, [1, 0]), (10, [1]), (11, [1]), (12, [1])]\n",
      "Phi value: [(0, [(0, 0.027115483), (1, 0.97288454)]), (10, [(1, 0.99823654)]), (11, [(1, 0.99825257)]), (12, [(1, 0.99495113)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.1358223), (1, 0.8641777)]\n",
      "Word topic: [(0, [1, 0]), (11, [1]), (13, [1])]\n",
      "Phi value: [(0, [(0, 0.037102651), (1, 0.9628973)]), (11, [(1, 0.99758583)]), (13, [(1, 0.99635386)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.18805583), (1, 0.81194419)]\n",
      "Word topic: [(0, [1, 0]), (10, [1])]\n",
      "Phi value: [(0, [(0, 0.059976365), (1, 0.9400236)]), (10, [(1, 0.99597222)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.10637136), (1, 0.89362872)]\n",
      "Word topic: [(0, [1, 0]), (10, [1]), (11, [1]), (14, [1])]\n",
      "Phi value: [(0, [(0, 0.026640313), (1, 0.97335976)]), (10, [(1, 0.99826819)]), (11, [(1, 0.99828392)]), (14, [(1, 0.99827129)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.16921233), (1, 0.83078766)]\n",
      "Word topic: [(13, [1]), (14, [1])]\n",
      "Phi value: [(13, [(1, 0.99542695)]), (14, [(1, 0.99694842)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topic: [(0, 0.13688906), (1, 0.86311096)]\n",
      "Word topic: [(0, [1, 0]), (14, [1]), (15, [1])]\n",
      "Phi value: [(0, [(0, 0.037809595), (1, 0.96219045)]), (14, [(1, 0.99751979)]), (15, [(1, 0.99280715)])]\n",
      " \n",
      "-------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in all_topics:\n",
    "    print('New Document \\n')\n",
    "    print 'Document topic:', doc[0]\n",
    "    print 'Word topic:', doc[1]\n",
    "    print 'Phi value:', doc[2]\n",
    "    print(\" \")\n",
    "    print('-------------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and interpreatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can compute the topic coherence of each topic. Below we display the average topic coherence and print the topics in order of topic coherence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use the \"Umass\" topic coherence measure here (see docs, https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.top_topics), Gensim has recently obtained an implementation of the \"AKSW\" topic coherence measure (see accompanying blog post, http://rare-technologies.com/what-is-topic-coherence/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -3.5992.\n",
      "[([(0.18381169, u'water'),\n",
      "   (0.15034011, u'river'),\n",
      "   (0.1473269, u'bank'),\n",
      "   (0.083456308, u'flow'),\n",
      "   (0.083444633, u'tree')],\n",
      "  -3.5424295468056668),\n",
      " ([(0.21429448, u'bank'),\n",
      "   (0.1337216, u'money'),\n",
      "   (0.13366649, u'sell'),\n",
      "   (0.13365366, u'finance'),\n",
      "   (0.095357426, u'borrow')],\n",
      "  -3.6559046803328732)]\n"
     ]
    }
   ],
   "source": [
    "num_topics=2\n",
    "top_topics = model.top_topics(corpus, topn=5)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'bank', 0.21429448),\n",
       " (u'money', 0.1337216),\n",
       " (u'sell', 0.13366649),\n",
       " (u'finance', 0.13365366),\n",
       " (u'borrow', 0.095357426)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topic(topicno, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'water', u'river', u'bank', u'flow', u'tree'], [u'bank', u'money', u'sell', u'finance', u'borrow']]\n"
     ]
    }
   ],
   "source": [
    "# select top 5 words for each of the 2 LDA topics\n",
    "top_words = [[word for word, _  in model.show_topic(topicno, topn=5)] for topicno in range(model.num_topics)]\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic coherence pipeline\n",
    "https://nbviewer.jupyter.org/github/dsquareindia/gensim/blob/280375fe14adea67ce6384ba7eabf362b05e6029/docs/notebooks/topic_coherence_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import pyLDAvis.gensim\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up corpus\n",
    "As stated in table 2 from this paper http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf , this corpus essentially has two classes of documents. First five are about human-computer interaction and the other four are about graphs. We will be setting up two LDA models. One with 50 iterations of training and the other with just 1. Hence the one with 50 iterations (\"better\" model) should be able to capture this underlying pattern of the corpus better than the \"bad\" LDA model. Therefore, in theory, our topic coherence for the good LDA model should be greater than the one for the bad LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up two topic models\n",
    "We'll be setting up two different LDA Topic models. A good one and bad one. To build a \"good\" topic model, we'll simply train it using more iterations than the bad one. Therefore the u_mass coherence should in theory be better for the good model than the bad one since it would be producing more \"human-interpretable\" topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.5\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.5\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (multi-pass) LDA training, 2 topics, 50 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 100x with a convergence threshold of 0.001000\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.296 per-word bound, 9.8 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:8/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.177*\"system\" + 0.115*\"eps\" + 0.104*\"interface\" + 0.102*\"human\" + 0.096*\"trees\" + 0.081*\"user\" + 0.074*\"computer\" + 0.072*\"graph\" + 0.050*\"survey\" + 0.050*\"minors\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.122*\"graph\" + 0.113*\"user\" + 0.107*\"response\" + 0.105*\"time\" + 0.099*\"trees\" + 0.096*\"minors\" + 0.096*\"survey\" + 0.072*\"computer\" + 0.069*\"system\" + 0.045*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.510348, rho=1.000000\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.065 per-word bound, 8.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.192*\"system\" + 0.127*\"eps\" + 0.122*\"interface\" + 0.121*\"human\" + 0.082*\"user\" + 0.080*\"computer\" + 0.078*\"trees\" + 0.053*\"graph\" + 0.039*\"survey\" + 0.039*\"minors\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.136*\"graph\" + 0.114*\"trees\" + 0.111*\"user\" + 0.108*\"response\" + 0.107*\"time\" + 0.102*\"minors\" + 0.102*\"survey\" + 0.068*\"computer\" + 0.062*\"system\" + 0.032*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.222631, rho=0.577350\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.003 per-word bound, 8.0 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.202*\"system\" + 0.134*\"eps\" + 0.130*\"interface\" + 0.130*\"human\" + 0.084*\"user\" + 0.084*\"computer\" + 0.060*\"trees\" + 0.042*\"graph\" + 0.035*\"survey\" + 0.035*\"minors\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.142*\"graph\" + 0.128*\"trees\" + 0.108*\"user\" + 0.107*\"response\" + 0.107*\"time\" + 0.104*\"minors\" + 0.104*\"survey\" + 0.065*\"computer\" + 0.057*\"system\" + 0.027*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.137969, rho=0.500000\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.976 per-word bound, 7.9 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.209*\"system\" + 0.137*\"eps\" + 0.135*\"interface\" + 0.135*\"human\" + 0.087*\"computer\" + 0.086*\"user\" + 0.049*\"trees\" + 0.037*\"graph\" + 0.033*\"survey\" + 0.032*\"minors\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.146*\"graph\" + 0.136*\"trees\" + 0.107*\"user\" + 0.107*\"response\" + 0.107*\"time\" + 0.106*\"minors\" + 0.105*\"survey\" + 0.062*\"computer\" + 0.053*\"system\" + 0.025*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.087151, rho=0.447214\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.964 per-word bound, 7.8 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.215*\"system\" + 0.138*\"eps\" + 0.137*\"interface\" + 0.136*\"human\" + 0.090*\"computer\" + 0.087*\"user\" + 0.042*\"trees\" + 0.034*\"graph\" + 0.032*\"survey\" + 0.031*\"minors\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.148*\"graph\" + 0.141*\"trees\" + 0.107*\"response\" + 0.107*\"time\" + 0.106*\"minors\" + 0.106*\"user\" + 0.106*\"survey\" + 0.060*\"computer\" + 0.049*\"system\" + 0.024*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.057703, rho=0.408248\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.958 per-word bound, 7.8 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.219*\"system\" + 0.138*\"eps\" + 0.137*\"interface\" + 0.137*\"human\" + 0.092*\"computer\" + 0.088*\"user\" + 0.037*\"trees\" + 0.032*\"graph\" + 0.031*\"survey\" + 0.030*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.149*\"graph\" + 0.145*\"trees\" + 0.107*\"minors\" + 0.107*\"response\" + 0.107*\"time\" + 0.106*\"survey\" + 0.105*\"user\" + 0.059*\"computer\" + 0.046*\"system\" + 0.023*\"human\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.039981, rho=0.377964\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.955 per-word bound, 7.8 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.222*\"system\" + 0.138*\"eps\" + 0.137*\"human\" + 0.137*\"interface\" + 0.094*\"computer\" + 0.089*\"user\" + 0.035*\"trees\" + 0.031*\"graph\" + 0.030*\"survey\" + 0.030*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.150*\"graph\" + 0.147*\"trees\" + 0.108*\"minors\" + 0.107*\"response\" + 0.107*\"time\" + 0.107*\"survey\" + 0.105*\"user\" + 0.057*\"computer\" + 0.043*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.028992, rho=0.353553\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.953 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.224*\"system\" + 0.137*\"eps\" + 0.137*\"human\" + 0.137*\"interface\" + 0.096*\"computer\" + 0.089*\"user\" + 0.033*\"trees\" + 0.030*\"survey\" + 0.030*\"graph\" + 0.030*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.151*\"graph\" + 0.149*\"trees\" + 0.108*\"minors\" + 0.108*\"response\" + 0.108*\"time\" + 0.108*\"survey\" + 0.104*\"user\" + 0.055*\"computer\" + 0.041*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.022204, rho=0.333333\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.951 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.226*\"system\" + 0.137*\"eps\" + 0.136*\"human\" + 0.136*\"interface\" + 0.097*\"computer\" + 0.090*\"user\" + 0.031*\"trees\" + 0.030*\"survey\" + 0.030*\"time\" + 0.029*\"response\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.152*\"graph\" + 0.151*\"trees\" + 0.109*\"minors\" + 0.108*\"response\" + 0.108*\"time\" + 0.108*\"survey\" + 0.104*\"user\" + 0.054*\"computer\" + 0.039*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017609, rho=0.316228\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.950 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.227*\"system\" + 0.136*\"eps\" + 0.136*\"human\" + 0.136*\"interface\" + 0.099*\"computer\" + 0.091*\"user\" + 0.030*\"trees\" + 0.030*\"survey\" + 0.029*\"time\" + 0.029*\"response\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.153*\"graph\" + 0.152*\"trees\" + 0.110*\"minors\" + 0.109*\"response\" + 0.108*\"time\" + 0.108*\"survey\" + 0.103*\"user\" + 0.052*\"computer\" + 0.037*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014391, rho=0.301511\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.949 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 10, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.228*\"system\" + 0.136*\"eps\" + 0.135*\"human\" + 0.135*\"interface\" + 0.100*\"computer\" + 0.091*\"user\" + 0.030*\"trees\" + 0.029*\"survey\" + 0.029*\"time\" + 0.029*\"response\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.154*\"graph\" + 0.153*\"trees\" + 0.110*\"minors\" + 0.109*\"response\" + 0.109*\"time\" + 0.109*\"survey\" + 0.103*\"user\" + 0.051*\"computer\" + 0.036*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012263, rho=0.288675\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.948 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 11, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.135*\"eps\" + 0.135*\"human\" + 0.135*\"interface\" + 0.102*\"computer\" + 0.092*\"user\" + 0.029*\"survey\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.155*\"graph\" + 0.154*\"trees\" + 0.110*\"minors\" + 0.109*\"response\" + 0.109*\"time\" + 0.109*\"survey\" + 0.103*\"user\" + 0.050*\"computer\" + 0.034*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.010639, rho=0.277350\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.948 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 12, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.135*\"eps\" + 0.134*\"human\" + 0.134*\"interface\" + 0.103*\"computer\" + 0.092*\"user\" + 0.029*\"survey\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.155*\"graph\" + 0.154*\"trees\" + 0.111*\"minors\" + 0.109*\"response\" + 0.109*\"time\" + 0.109*\"survey\" + 0.102*\"user\" + 0.049*\"computer\" + 0.033*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.009355, rho=0.267261\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.947 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 13, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.134*\"eps\" + 0.134*\"human\" + 0.134*\"interface\" + 0.104*\"computer\" + 0.092*\"user\" + 0.029*\"time\" + 0.029*\"survey\" + 0.029*\"response\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.156*\"graph\" + 0.155*\"trees\" + 0.111*\"minors\" + 0.110*\"response\" + 0.110*\"survey\" + 0.110*\"time\" + 0.102*\"user\" + 0.048*\"computer\" + 0.032*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.008460, rho=0.258199\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.947 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 14, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.134*\"eps\" + 0.134*\"human\" + 0.134*\"interface\" + 0.105*\"computer\" + 0.093*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.156*\"graph\" + 0.156*\"trees\" + 0.111*\"minors\" + 0.110*\"survey\" + 0.110*\"response\" + 0.110*\"time\" + 0.102*\"user\" + 0.047*\"computer\" + 0.031*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.007675, rho=0.250000\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.947 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 15, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.133*\"eps\" + 0.133*\"human\" + 0.133*\"interface\" + 0.106*\"computer\" + 0.093*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.156*\"graph\" + 0.156*\"trees\" + 0.112*\"minors\" + 0.110*\"survey\" + 0.110*\"response\" + 0.110*\"time\" + 0.101*\"user\" + 0.046*\"computer\" + 0.031*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.006978, rho=0.242536\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.946 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 16, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.133*\"eps\" + 0.133*\"human\" + 0.133*\"interface\" + 0.107*\"computer\" + 0.093*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.157*\"graph\" + 0.156*\"trees\" + 0.112*\"minors\" + 0.110*\"survey\" + 0.110*\"response\" + 0.110*\"time\" + 0.101*\"user\" + 0.045*\"computer\" + 0.030*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.006360, rho=0.235702\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.946 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 17, at document #9/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.133*\"eps\" + 0.133*\"human\" + 0.133*\"interface\" + 0.108*\"computer\" + 0.094*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.157*\"graph\" + 0.157*\"trees\" + 0.112*\"minors\" + 0.110*\"survey\" + 0.110*\"response\" + 0.110*\"time\" + 0.101*\"user\" + 0.044*\"computer\" + 0.030*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.005804, rho=0.229416\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.946 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 18, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.132*\"eps\" + 0.132*\"human\" + 0.132*\"interface\" + 0.109*\"computer\" + 0.094*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.028*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.158*\"graph\" + 0.157*\"trees\" + 0.112*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.101*\"user\" + 0.043*\"computer\" + 0.029*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.005312, rho=0.223607\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.946 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 19, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.132*\"eps\" + 0.132*\"human\" + 0.132*\"interface\" + 0.109*\"computer\" + 0.094*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.158*\"graph\" + 0.157*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.100*\"user\" + 0.042*\"computer\" + 0.029*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.004871, rho=0.218218\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 20, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.132*\"eps\" + 0.132*\"human\" + 0.132*\"interface\" + 0.110*\"computer\" + 0.094*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.158*\"graph\" + 0.158*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.100*\"user\" + 0.042*\"computer\" + 0.029*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.004476, rho=0.213201\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 21, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.132*\"eps\" + 0.132*\"human\" + 0.132*\"interface\" + 0.111*\"computer\" + 0.095*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.158*\"graph\" + 0.158*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.100*\"user\" + 0.041*\"computer\" + 0.028*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.004121, rho=0.208514\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 22, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.111*\"computer\" + 0.095*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.158*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.100*\"user\" + 0.040*\"computer\" + 0.028*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.003802, rho=0.204124\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 23, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.112*\"computer\" + 0.095*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.158*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.100*\"user\" + 0.040*\"computer\" + 0.028*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.003516, rho=0.200000\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 24, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.112*\"computer\" + 0.095*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.159*\"trees\" + 0.113*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.099*\"user\" + 0.039*\"computer\" + 0.028*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.003256, rho=0.196116\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 25, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.113*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.159*\"trees\" + 0.114*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.099*\"user\" + 0.039*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.003018, rho=0.192450\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:PROGRESS: pass 26, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.231*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.113*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.159*\"trees\" + 0.114*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.099*\"user\" + 0.038*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.002803, rho=0.188982\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 27, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.131*\"eps\" + 0.131*\"human\" + 0.131*\"interface\" + 0.114*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.159*\"graph\" + 0.159*\"trees\" + 0.114*\"minors\" + 0.111*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.099*\"user\" + 0.038*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.002605, rho=0.185695\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 28, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.114*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.159*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.111*\"response\" + 0.111*\"time\" + 0.099*\"user\" + 0.037*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.002424, rho=0.182574\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 29, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.114*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.159*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.099*\"user\" + 0.037*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.002255, rho=0.179605\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 30, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.115*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.099*\"user\" + 0.037*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.002103, rho=0.176777\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 31, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.115*\"computer\" + 0.096*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.099*\"user\" + 0.036*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001958, rho=0.174078\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 32, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.115*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.036*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001829, rho=0.171499\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.945 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 33, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.116*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.036*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001708, rho=0.169031\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 34, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.116*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.036*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001595, rho=0.166667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 35, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.116*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.035*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001494, rho=0.164399\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 36, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.116*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.114*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.035*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001398, rho=0.162221\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 37, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.116*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.160*\"graph\" + 0.160*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.035*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001311, rho=0.160128\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 38, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.130*\"human\" + 0.130*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.160*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.035*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001227, rho=0.158114\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 39, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.130*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.029*\"time\" + 0.029*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.160*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001150, rho=0.156174\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 40, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.230*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.160*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.027*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001079, rho=0.154303\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 41, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.160*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.001012, rho=0.152499\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 42, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000952, rho=0.150756\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 43, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.117*\"computer\" + 0.097*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic diff=0.000895, rho=0.149071\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 44, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.097*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000842, rho=0.147442\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 45, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.034*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000790, rho=0.145865\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 46, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.098*\"user\" + 0.033*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000744, rho=0.144338\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 47, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.097*\"user\" + 0.033*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000700, rho=0.142857\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 48, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.097*\"user\" + 0.033*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000660, rho=0.141421\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-2.944 per-word bound, 7.7 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 49, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 100 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.097*\"user\" + 0.033*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.000624, rho=0.140028\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.5\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.5\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.309 per-word bound, 9.9 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:0/9 documents converged within 1 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.113*\"trees\" + 0.109*\"user\" + 0.098*\"graph\" + 0.093*\"system\" + 0.088*\"minors\" + 0.081*\"eps\" + 0.077*\"survey\" + 0.076*\"time\" + 0.072*\"computer\" + 0.071*\"interface\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.148*\"system\" + 0.097*\"graph\" + 0.087*\"user\" + 0.084*\"human\" + 0.084*\"response\" + 0.084*\"trees\" + 0.075*\"interface\" + 0.074*\"computer\" + 0.070*\"time\" + 0.070*\"survey\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.254907, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=100, num_topics=2,passes=50)\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using U_Mass Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.coherencemodel:Setting topics to those of the model: LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000)\n",
      "DEBUG:gensim.models.coherencemodel:Setting topics to those of the model: LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "badcm = CoherenceModel(model=badLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_pre at 0x000000000D8DA358>, prob=<function p_boolean_document at 0x000000000D8E7BA8>, conf=<function log_conditional_probability at 0x000000000D9906D8>, aggr=<function arithmetic_mean at 0x000000000D990908>)\n"
     ]
    }
   ],
   "source": [
    "print goodcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the topics\n",
    "As we will see below using LDA visualization, the better model comes up with two topics composed of the following words:\n",
    "\n",
    "goodLdaModel:\n",
    "- Topic 1: More weightage assigned to words such as \"system\", \"user\", \"eps\", \"interface\" etc which captures the first set of documents.\n",
    "- Topic 2: More weightage assigned to words such as \"graph\", \"trees\", \"survey\" which captures the topic in the second set of documents.\n",
    "<br>badLdaModel:\n",
    "- Topic 1: More weightage assigned to words such as \"system\", \"user\", \"trees\", \"graph\" which doesn't make the topic clear enough.\n",
    "- Topic 2: More weightage assigned to words such as \"system\", \"trees\", \"graph\", \"user\" which is similar to the first topic. Hence both topics are not human-interpretable.\n",
    "<br>Therefore, the topic coherence for the goodLdaModel should be greater for this than the badLdaModel since the topics it comes up with are more human-interpretable. We will see this using u_mass and c_v topic coherence measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.229*\"system\" + 0.129*\"eps\" + 0.129*\"human\" + 0.129*\"interface\" + 0.118*\"computer\" + 0.098*\"user\" + 0.030*\"time\" + 0.030*\"response\" + 0.029*\"survey\" + 0.027*\"trees\"'), (1, u'0.161*\"graph\" + 0.161*\"trees\" + 0.115*\"minors\" + 0.112*\"survey\" + 0.112*\"response\" + 0.112*\"time\" + 0.097*\"user\" + 0.033*\"computer\" + 0.026*\"system\" + 0.023*\"interface\"')]\n",
      "[(0, u'0.113*\"trees\" + 0.109*\"user\" + 0.098*\"graph\" + 0.093*\"system\" + 0.088*\"minors\" + 0.081*\"eps\" + 0.077*\"survey\" + 0.076*\"time\" + 0.072*\"computer\" + 0.071*\"interface\"'), (1, u'0.148*\"system\" + 0.097*\"graph\" + 0.087*\"user\" + 0.084*\"human\" + 0.084*\"response\" + 0.084*\"trees\" + 0.075*\"interface\" + 0.074*\"computer\" + 0.070*\"time\" + 0.070*\"survey\"')]\n"
     ]
    }
   ],
   "source": [
    "print goodLdaModel.show_topics()\n",
    "print badLdaModel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 50 iterations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el89922902911688436070489\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el89922902911688436070489_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1], \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.4761496359814009, 0.4761496359814009, 0.4601982284036394, 0.4601982284036394, 0.371518632480768, 0.743037264961536, 0.49228587452070716, 0.49228587452070716, 0.47539633533564374, 0.47539633533564374, 0.4867083819491124, 0.4867083819491124, 0.9153396959020085, 0.45766984795100424, 0.9078731046343823, 0.45393655231719116, 0.8230089558717879, 0.2743363186239293, 0.9057557169446597, 0.45287785847232986, 0.37915020950667067, 0.7583004190133413, 0.6740701172781257, 0.33703505863906286], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"mdsDat\": {\"y\": [0.0, 0.0], \"cluster\": [1, 1], \"Freq\": [58.974047550627304, 41.02595244937269], \"topics\": [1, 2], \"x\": [0.027242740616202354, -0.027242740616202354]}, \"R\": 12, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Term\": [\"trees\", \"graph\", \"human\", \"minors\", \"user\", \"computer\", \"interface\", \"time\", \"survey\", \"system\", \"response\", \"eps\", \"user\", \"time\", \"survey\", \"system\", \"response\", \"eps\", \"interface\", \"computer\", \"minors\", \"human\", \"graph\", \"trees\", \"trees\", \"graph\", \"human\", \"minors\", \"computer\", \"interface\", \"eps\", \"response\", \"system\", \"survey\", \"time\", \"user\"], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2721, 0.2333, 0.2213, 0.1828, 0.1776, 0.1468, -0.0609, -0.0724, -0.2494, -0.3573, -0.4221, -0.6729, 0.533, 0.4021, 0.359, 0.2756, 0.0956, 0.0815, -0.2579, -0.3275, -0.3402, -0.44, -0.4744, -0.5971], \"Freq\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.297076423889809, 1.6444034070595697, 1.6209107447786302, 2.5809736271818107, 1.5389339466686425, 1.4841710825924164, 1.1672656228993037, 1.1520841491568459, 0.9442378569901428, 0.8380447593480078, 1.040761050825328, 0.7936107052639747, 1.8438664078336149, 1.6508939903300197, 1.1932952643193515, 1.1103805492006806, 0.9480959716131331, 0.936242388566478, 0.6888055572109448, 0.646047223659744, 1.0641871922678305, 0.5820402951747319, 0.5636974777424602, 0.6699739596458658], \"Total\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.9670503835356747, 2.20810088480203, 2.202951039953362, 3.645160819449641, 2.1849811703283866, 2.172976639803361, 2.103508011465782, 2.100180120769979, 2.0546184061908237, 2.0313400236673593, 2.6916550411553475, 2.6374771130975896, 2.6374771130975896, 2.6916550411553475, 2.0313400236673593, 2.0546184061908237, 2.100180120769979, 2.103508011465782, 2.172976639803361, 2.1849811703283866, 3.645160819449641, 2.202951039953362, 2.20810088480203, 2.9670503835356747], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.0076000690460205, -2.3417999744415283, -2.3561999797821045, -1.8911000490188599, -2.408099889755249, -2.4444000720977783, -2.6846001148223877, -2.697700023651123, -2.8966000080108643, -3.015899896621704, -2.799299955368042, -3.0703999996185303, -1.8645000457763672, -1.975000023841858, -2.2995998859405518, -2.3715999126434326, -2.529599905014038, -2.5422000885009766, -2.849100112915039, -2.9131999015808105, -2.414099931716919, -3.0174999237060547, -3.0495998859405518, -2.876800060272217]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el89922902911688436070489\", ldavis_el89922902911688436070489_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el89922902911688436070489\", ldavis_el89922902911688436070489_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el89922902911688436070489\", ldavis_el89922902911688436070489_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "1      58.974048        1       1  0.027243  0.0\n",
       "0      41.025952        1       2 -0.027243  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "3     Default  2.000000      trees  2.000000  12.0000  12.0000\n",
       "1     Default  2.000000      graph  2.000000  11.0000  11.0000\n",
       "8     Default  2.000000      human  2.000000  10.0000  10.0000\n",
       "0     Default  2.000000     minors  2.000000   9.0000   9.0000\n",
       "7     Default  2.000000       user  2.000000   8.0000   8.0000\n",
       "5     Default  2.000000   computer  2.000000   7.0000   7.0000\n",
       "10    Default  2.000000  interface  2.000000   6.0000   6.0000\n",
       "9     Default  2.000000       time  2.000000   5.0000   5.0000\n",
       "6     Default  2.000000     survey  2.000000   4.0000   4.0000\n",
       "2     Default  3.000000     system  3.000000   3.0000   3.0000\n",
       "11    Default  2.000000   response  2.000000   2.0000   2.0000\n",
       "4     Default  2.000000        eps  2.000000   1.0000   1.0000\n",
       "7      Topic1  2.297076       user  2.967050   0.2721  -2.0076\n",
       "9      Topic1  1.644403       time  2.208101   0.2333  -2.3418\n",
       "6      Topic1  1.620911     survey  2.202951   0.2213  -2.3562\n",
       "2      Topic1  2.580974     system  3.645161   0.1828  -1.8911\n",
       "11     Topic1  1.538934   response  2.184981   0.1776  -2.4081\n",
       "4      Topic1  1.484171        eps  2.172977   0.1468  -2.4444\n",
       "10     Topic1  1.167266  interface  2.103508  -0.0609  -2.6846\n",
       "5      Topic1  1.152084   computer  2.100180  -0.0724  -2.6977\n",
       "0      Topic1  0.944238     minors  2.054618  -0.2494  -2.8966\n",
       "8      Topic1  0.838045      human  2.031340  -0.3573  -3.0159\n",
       "1      Topic1  1.040761      graph  2.691655  -0.4221  -2.7993\n",
       "3      Topic1  0.793611      trees  2.637477  -0.6729  -3.0704\n",
       "3      Topic2  1.843866      trees  2.637477   0.5330  -1.8645\n",
       "1      Topic2  1.650894      graph  2.691655   0.4021  -1.9750\n",
       "8      Topic2  1.193295      human  2.031340   0.3590  -2.2996\n",
       "0      Topic2  1.110381     minors  2.054618   0.2756  -2.3716\n",
       "5      Topic2  0.948096   computer  2.100180   0.0956  -2.5296\n",
       "10     Topic2  0.936242  interface  2.103508   0.0815  -2.5422\n",
       "4      Topic2  0.688806        eps  2.172977  -0.2579  -2.8491\n",
       "11     Topic2  0.646047   response  2.184981  -0.3275  -2.9132\n",
       "2      Topic2  1.064187     system  3.645161  -0.3402  -2.4141\n",
       "6      Topic2  0.582040     survey  2.202951  -0.4400  -3.0175\n",
       "9      Topic2  0.563697       time  2.208101  -0.4744  -3.0496\n",
       "7      Topic2  0.669974       user  2.967050  -0.5971  -2.8768, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "5         1  0.476150   computer\n",
       "5         2  0.476150   computer\n",
       "4         1  0.460198        eps\n",
       "4         2  0.460198        eps\n",
       "1         1  0.371519      graph\n",
       "1         2  0.743037      graph\n",
       "8         1  0.492286      human\n",
       "8         2  0.492286      human\n",
       "10        1  0.475396  interface\n",
       "10        2  0.475396  interface\n",
       "0         1  0.486708     minors\n",
       "0         2  0.486708     minors\n",
       "11        1  0.915340   response\n",
       "11        2  0.457670   response\n",
       "6         1  0.907873     survey\n",
       "6         2  0.453937     survey\n",
       "2         1  0.823009     system\n",
       "2         2  0.274336     system\n",
       "9         1  0.905756       time\n",
       "9         2  0.452878       time\n",
       "3         1  0.379150      trees\n",
       "3         2  0.758300      trees\n",
       "7         1  0.674070       user\n",
       "7         2  0.337035       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(goodLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:0/9 documents converged within 1 iterations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el89922885352004719535239\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el89922885352004719535239_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2], \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.47277208236965457, 0.47277208236965457, 0.47245732848202954, 0.47245732848202954, 0.7042600895391328, 0.3521300447695664, 0.47182190183376, 0.47182190183376, 0.4713672500484761, 0.4713672500484761, 0.46918299015234266, 0.46918299015234266, 0.4740392662861199, 0.4740392662861199, 0.4714019368583785, 0.4714019368583785, 0.5646837261749291, 0.5646837261749291, 0.4721052167647662, 0.4721052167647662, 0.7034711267178435, 0.35173556335892175, 0.3543358031808047, 0.3543358031808047], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"mdsDat\": {\"y\": [0.0, 0.0], \"cluster\": [1, 1], \"Freq\": [52.52839394436333, 47.47160605563667], \"topics\": [1, 2], \"x\": [0.002758220303803682, -0.002758220303803682]}, \"R\": 12, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Term\": [\"response\", \"computer\", \"user\", \"eps\", \"trees\", \"time\", \"minors\", \"human\", \"graph\", \"survey\", \"interface\", \"system\", \"trees\", \"minors\", \"graph\", \"system\", \"interface\", \"survey\", \"human\", \"time\", \"user\", \"eps\", \"computer\", \"response\", \"response\", \"computer\", \"eps\", \"user\", \"time\", \"human\", \"survey\", \"interface\", \"system\", \"graph\", \"minors\", \"trees\"], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.1416, 0.1298, 0.1107, 0.0452, -0.0069, -0.0092, -0.0378, -0.0576, -0.0821, -0.0828, -0.1058, -0.2043, 0.186, 0.1053, 0.0842, 0.0836, 0.0601, 0.0403, 0.0101, 0.0076, -0.0525, -0.1387, -0.1665, -0.1842], \"Freq\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.7204925208600397, 1.2747349156647518, 1.666317946545969, 1.9465011580115128, 1.1067503115535193, 1.104096310820767, 1.0719802234385014, 1.0503445107424774, 1.3656341002721986, 1.0234971550577752, 0.9995279555731185, 0.9033587340590582, 1.2061711532739912, 1.1156561622955685, 1.0930961110746944, 1.4565475450009897, 1.0678273807964072, 1.047463566926992, 1.0172356604995505, 1.014737763609018, 1.5953044710397393, 1.1735419712704704, 0.8566296499502593, 1.122552380401677], \"Total\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.8430449012617167, 2.1313645656150113, 2.8398599178164394, 3.541805629051252, 2.1214880751625373, 2.1213319713203176, 2.1194437903654935, 2.1181718915388847, 2.8221816452731883, 2.11659326613247, 2.115184117868687, 2.1095298873330495, 2.1095298873330495, 2.115184117868687, 2.11659326613247, 2.8221816452731883, 2.1181718915388847, 2.1194437903654935, 2.1213319713203176, 2.1214880751625373, 3.541805629051252, 2.8398599178164394, 2.1313645656150113, 2.8430449012617167], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.1809000968933105, -2.4807000160217285, -2.212899923324585, -2.0573999881744385, -2.6221001148223877, -2.624500036239624, -2.6540000438690186, -2.6744000911712646, -2.411900043487549, -2.7002999782562256, -2.7239999771118164, -2.8250999450683594, -2.434799909591675, -2.5127999782562256, -2.5332000255584717, -2.2462000846862793, -2.5566000938415527, -2.575900077819824, -2.6052000522613525, -2.607599973678589, -2.1552000045776367, -2.4621999263763428, -2.7769999504089355, -2.506700038909912]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el89922885352004719535239\", ldavis_el89922885352004719535239_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el89922885352004719535239\", ldavis_el89922885352004719535239_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el89922885352004719535239\", ldavis_el89922885352004719535239_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "0      52.528394        1       1  0.002758  0.0\n",
       "1      47.471606        1       2 -0.002758  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "11    Default  2.000000   response  2.000000  12.0000  12.0000\n",
       "5     Default  2.000000   computer  2.000000  11.0000  11.0000\n",
       "7     Default  2.000000       user  2.000000  10.0000  10.0000\n",
       "4     Default  2.000000        eps  2.000000   9.0000   9.0000\n",
       "3     Default  2.000000      trees  2.000000   8.0000   8.0000\n",
       "9     Default  2.000000       time  2.000000   7.0000   7.0000\n",
       "0     Default  2.000000     minors  2.000000   6.0000   6.0000\n",
       "8     Default  2.000000      human  2.000000   5.0000   5.0000\n",
       "1     Default  2.000000      graph  2.000000   4.0000   4.0000\n",
       "6     Default  2.000000     survey  2.000000   3.0000   3.0000\n",
       "10    Default  2.000000  interface  2.000000   2.0000   2.0000\n",
       "2     Default  3.000000     system  3.000000   1.0000   1.0000\n",
       "3      Topic1  1.720493      trees  2.843045   0.1416  -2.1809\n",
       "0      Topic1  1.274735     minors  2.131365   0.1298  -2.4807\n",
       "1      Topic1  1.666318      graph  2.839860   0.1107  -2.2129\n",
       "2      Topic1  1.946501     system  3.541806   0.0452  -2.0574\n",
       "10     Topic1  1.106750  interface  2.121488  -0.0069  -2.6221\n",
       "6      Topic1  1.104096     survey  2.121332  -0.0092  -2.6245\n",
       "8      Topic1  1.071980      human  2.119444  -0.0378  -2.6540\n",
       "9      Topic1  1.050345       time  2.118172  -0.0576  -2.6744\n",
       "7      Topic1  1.365634       user  2.822182  -0.0821  -2.4119\n",
       "4      Topic1  1.023497        eps  2.116593  -0.0828  -2.7003\n",
       "5      Topic1  0.999528   computer  2.115184  -0.1058  -2.7240\n",
       "11     Topic1  0.903359   response  2.109530  -0.2043  -2.8251\n",
       "11     Topic2  1.206171   response  2.109530   0.1860  -2.4348\n",
       "5      Topic2  1.115656   computer  2.115184   0.1053  -2.5128\n",
       "4      Topic2  1.093096        eps  2.116593   0.0842  -2.5332\n",
       "7      Topic2  1.456548       user  2.822182   0.0836  -2.2462\n",
       "9      Topic2  1.067827       time  2.118172   0.0601  -2.5566\n",
       "8      Topic2  1.047464      human  2.119444   0.0403  -2.5759\n",
       "6      Topic2  1.017236     survey  2.121332   0.0101  -2.6052\n",
       "10     Topic2  1.014738  interface  2.121488   0.0076  -2.6076\n",
       "2      Topic2  1.595304     system  3.541806  -0.0525  -2.1552\n",
       "1      Topic2  1.173542      graph  2.839860  -0.1387  -2.4622\n",
       "0      Topic2  0.856630     minors  2.131365  -0.1665  -2.7770\n",
       "3      Topic2  1.122552      trees  2.843045  -0.1842  -2.5067, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "5         1  0.472772   computer\n",
       "5         2  0.472772   computer\n",
       "4         1  0.472457        eps\n",
       "4         2  0.472457        eps\n",
       "1         1  0.704260      graph\n",
       "1         2  0.352130      graph\n",
       "8         1  0.471822      human\n",
       "8         2  0.471822      human\n",
       "10        1  0.471367  interface\n",
       "10        2  0.471367  interface\n",
       "0         1  0.469183     minors\n",
       "0         2  0.469183     minors\n",
       "11        1  0.474039   response\n",
       "11        2  0.474039   response\n",
       "6         1  0.471402     survey\n",
       "6         2  0.471402     survey\n",
       "2         1  0.564684     system\n",
       "2         2  0.564684     system\n",
       "9         1  0.472105       time\n",
       "9         2  0.472105       time\n",
       "3         1  0.703471      trees\n",
       "3         2  0.351736      trees\n",
       "7         1  0.354336       user\n",
       "7         2  0.354336       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(badLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.6431250635\n",
      "-14.7199176976\n"
     ]
    }
   ],
   "source": [
    "print goodcm.get_coherence()\n",
    "print badcm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.coherencemodel:Setting topics to those of the model: LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000)\n",
      "DEBUG:gensim.models.coherencemodel:Setting topics to those of the model: LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_set at 0x000000000D8DA438>, prob=<function p_boolean_sliding_window at 0x000000000D9904A8>, conf=<function cosine_similarity at 0x000000000D990DD8>, aggr=<function arithmetic_mean at 0x000000000D990908>)\n",
      "Coherence_Measure(seg=<function s_one_set at 0x000000000D8DA438>, prob=<function p_boolean_sliding_window at 0x000000000D9904A8>, conf=<function cosine_similarity at 0x000000000D990DD8>, aggr=<function arithmetic_mean at 0x000000000D990908>)\n"
     ]
    }
   ],
   "source": [
    "print goodcm\n",
    "print badcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:3 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 9 virtual documents\n",
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383841355374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.topic_coherence.text_analysis:3 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 9 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383841355374\n"
     ]
    }
   ],
   "source": [
    "print goodcm.get_coherence()\n",
    "print badcm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Hence as we can see, the u_mass and c_v coherence for the good LDA model is much more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable. The badLdaModel however fails to decipher between these two topics and comes up with topics which are not clear to a human. The u_mass and c_v topic coherences capture this wonderfully by giving the interpretability of these topics a number as we can see above. Hence this coherence measure can be used to compare difference topic models based on their human-interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit\n",
    "Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "http://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 63.461s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf-idf transformer is applied to the bag of words matrix that NMF must process with the TfidfVectorizer. \n",
    "<br>LDA on the other hand, being a probabilistic graphical model (i.e. dealing with probabilities) only requires raw counts, so a CountVectorizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.605s.\n",
      "Extracting tf features for LDA...\n",
      "done in 0.952s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 0.500s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 2.915s.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 4.666s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
    "<br>https://towardsdatascience.com/improving-the-interpretation-of-topic-models-87fd2ee3847d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import numpy as np\n",
    "\n",
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "trees graph minors survey\n",
      "Graph minors IV: Widths of trees and quasi-ordering\n",
      "The intersection graph of paths in trees\n",
      "The generation of random, binary, unordered trees\n",
      "Graph minors: A survey\n",
      "Topic 1:\n",
      "user time response interface\n",
      "A survey of user opinion of computer system response time\n",
      "Relation of user-perceived response time to error measurement\n",
      "The EPS user interface management system\n",
      "Human machine interface for Lab ABC computer applications\n",
      "Topic 0:\n",
      "user response time computer\n",
      "A survey of user opinion of computer system response time\n",
      "Relation of user-perceived response time to error measurement\n",
      "The EPS user interface management system\n",
      "Human machine interface for Lab ABC computer applications\n",
      "Topic 1:\n",
      "trees graph human minors\n",
      "Graph minors IV: Widths of trees and quasi-ordering\n",
      "Graph minors: A survey\n",
      "The intersection graph of paths in trees\n",
      "The generation of random, binary, unordered trees\n"
     ]
    }
   ],
   "source": [
    "# Single line documents from http://web.eecs.utk.edu/~berry/order/node4.html#SECTION00022000000000000000\n",
    "documents = [\n",
    "            \"Human machine interface for Lab ABC computer applications\",\n",
    "            \"A survey of user opinion of computer system response time\",\n",
    "            \"The EPS user interface management system\",\n",
    "            \"System and human system engineering testing of EPS\",\n",
    "            \"Relation of user-perceived response time to error measurement\",\n",
    "            \"The generation of random, binary, unordered trees\",\n",
    "            \"The intersection graph of paths in trees\",\n",
    "            \"Graph minors IV: Widths of trees and quasi-ordering\",\n",
    "            \"Graph minors: A survey\"\n",
    "            ]\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 2\n",
    "\n",
    "# Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)\n",
    "nmf_H = nmf_model.components_\n",
    "\n",
    "# Run LDA\n",
    "lda_model = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "no_top_words = 4\n",
    "no_top_documents = 4\n",
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, documents, no_top_words, no_top_documents)\n",
    "display_topics(lda_H, lda_W, tf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
