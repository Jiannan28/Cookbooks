{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Webscraping with Selenium and BeautifulSoup</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Scraping Singapore Urban Redevelopment Authority website to get private residential property transaction data </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is a web scraping bot that allows crwaling not only the static web pages but also dynamic generated contents (by javascript for example) from web pages. It act as a human being to takes control of your browser then navigate on the websites you want to crawl and get the data directly or via the help of BeautifulSoup which is another package to pulling date out of  html or xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loop parameters for scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locating html page elements with \"Inspect Element\" function of Chorm or FireFox. A page element usually has a few attributes - a name, an id, a CSS selector, an xpath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['//*[@id=\"addToPostal_0\"]', '//*[@id=\"addToPostal_1\"]', '//*[@id=\"addToPostal_2\"]', '//*[@id=\"addToPostal_3\"]', '//*[@id=\"addToPostal_4\"]'], 2: ['//*[@id=\"addToPostal_5\"]', '//*[@id=\"addToPostal_6\"]', '//*[@id=\"addToPostal_7\"]', '//*[@id=\"addToPostal_8\"]', '//*[@id=\"addToPostal_9\"]'], 3: ['//*[@id=\"addToPostal_10\"]', '//*[@id=\"addToPostal_11\"]', '//*[@id=\"addToPostal_12\"]', '//*[@id=\"addToPostal_13\"]', '//*[@id=\"addToPostal_14\"]'], 4: ['//*[@id=\"addToPostal_15\"]', '//*[@id=\"addToPostal_16\"]', '//*[@id=\"addToPostal_17\"]', '//*[@id=\"addToPostal_18\"]', '//*[@id=\"addToPostal_19\"]'], 5: ['//*[@id=\"addToPostal_20\"]', '//*[@id=\"addToPostal_21\"]', '//*[@id=\"addToPostal_22\"]', '//*[@id=\"addToPostal_23\"]', '//*[@id=\"addToPostal_24\"]'], 6: ['//*[@id=\"addToPostal_25\"]', '//*[@id=\"addToPostal_26\"]']}\n"
     ]
    }
   ],
   "source": [
    "#initiae loop\n",
    "postal_district_list = []\n",
    "for i in range(27) :\n",
    "    postal_district_list.append('//*[@id=\"addToPostal_' + str(i) + '\"]')\n",
    "\n",
    "# Define postal districts for crawling\n",
    "postal_dict = {\n",
    "    1 : postal_district_list[:5],\n",
    "    2 : postal_district_list[5:10],\n",
    "    3 : postal_district_list[10:15],\n",
    "    4 : postal_district_list[15:20],\n",
    "    5 : postal_district_list[20:25],\n",
    "    6 : postal_district_list[25:],\n",
    "}\n",
    "\n",
    "print postal_dict\n",
    "\n",
    "# Define property type\n",
    "p_types_list = ['//*[@id=\"district\"]/div[2]/div[1]/label',\n",
    "               '//*[@id=\"district\"]/div[2]/div[2]/label',\n",
    "               '//*[@id=\"district\"]/div[2]/div[3]/label',\n",
    "               '//*[@id=\"district\"]/div[2]/div[4]/label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the webdriver and website starting url to scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webdriver is browser specific, for chorm you can find at http://chromedriver.storage.googleapis.com/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize selenium chrom driver\n",
    "path_to_chromedriver = 'C:\\Users\\liuleo\\Documents\\Python\\chromedriver_win32\\chromedriver.exe' \n",
    "browser = webdriver.Chrome(executable_path = path_to_chromedriver)\n",
    "\n",
    "# navigate to the webpage containing information to be crawled\n",
    "url = 'https://www.ura.gov.sg/realEstateIIWeb/transaction/search.action'\n",
    "browser.get(url)\n",
    "\n",
    "# search by postal district\n",
    "browser.find_element_by_xpath('//*[@id=\"searchForm\"]/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling property type //*[@id=\"district\"]/div[2]/div[1]/label\n",
      "crawling postal zone 1\n",
      "round zone 1\n",
      "crawling postal zone 2\n",
      "round zone 2\n",
      "crawling postal zone 3\n",
      "round zone 3\n",
      "crawling postal zone 4\n",
      "round zone 4\n",
      "crawling postal zone 5\n",
      "round zone 5\n",
      "crawling postal zone 6\n",
      "round zone 6\n",
      "crawling property type //*[@id=\"district\"]/div[2]/div[2]/label\n",
      "crawling postal zone 1\n",
      "round zone 1\n",
      "crawling postal zone 2\n",
      "round zone 2\n",
      "crawling postal zone 3\n",
      "round zone 3\n",
      "crawling postal zone 4\n",
      "round zone 4\n",
      "crawling postal zone 5\n",
      "round zone 5\n",
      "crawling postal zone 6\n",
      "round zone 6\n",
      "crawling property type //*[@id=\"district\"]/div[2]/div[3]/label\n",
      "crawling postal zone 1\n",
      "round zone 1\n",
      "crawling postal zone 2\n",
      "round zone 2\n",
      "crawling postal zone 3\n",
      "round zone 3\n",
      "crawling postal zone 4\n",
      "round zone 4\n",
      "crawling postal zone 5\n",
      "round zone 5\n",
      "crawling postal zone 6\n",
      "round zone 6\n",
      "crawling property type //*[@id=\"district\"]/div[2]/div[4]/label\n",
      "crawling postal zone 4\n",
      "round zone 4\n",
      "crawling postal zone 5\n",
      "round zone 5\n",
      "crawling postal zone 6\n",
      "round zone 6\n"
     ]
    }
   ],
   "source": [
    "for p_types in p_types_list:\n",
    "    \n",
    "    print 'crawling property type {}'.format(p_types)\n",
    "    \n",
    "    if p_types == '//*[@id=\"district\"]/div[2]/div[4]/label':\n",
    "        postal_dict = {\n",
    "            4 : postal_district_list[15:20],\n",
    "            5 : postal_district_list[20:25],\n",
    "            6 : postal_district_list[25:] \n",
    "        }\n",
    "\n",
    "    for k, v in postal_dict.iteritems():\n",
    "\n",
    "        print 'crawling postal zone {}'.format(k)\n",
    "\n",
    "        #select property type\n",
    "        browser.find_element_by_xpath(p_types).click()\n",
    "\n",
    "        # select time range: open dropdown menu and select one date \n",
    "        # UPDATE the initial time for updating information\n",
    "        browser.find_element_by_xpath('//*[@id=\"searchForm_selectedFromPeriodPostalDistrict\"]/option[contains(text(), \"JAN 2015\")]').click()\n",
    "\n",
    "        #select all type of sale\n",
    "        browser.find_element_by_xpath('//*[@id=\"district\"]/div[3]/div[1]/label').click()\n",
    "        browser.find_element_by_xpath('//*[@id=\"district\"]/div[3]/div[2]/label').click()\n",
    "        browser.find_element_by_xpath('//*[@id=\"district\"]/div[3]/div[3]/label').click()\n",
    "\n",
    "        print 'round zone {}'.format(k)\n",
    "        #select postal districts\n",
    "        browser.find_element_by_xpath(v[0]).click()\n",
    "        browser.find_element_by_xpath(v[1]).click()\n",
    "        \n",
    "        if k < 6:\n",
    "            browser.find_element_by_xpath(v[2]).click()\n",
    "            browser.find_element_by_xpath(v[3]).click()\n",
    "            browser.find_element_by_xpath(v[4]).click()\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "        #click search\n",
    "        browser.find_element_by_xpath('//*[@id=\"searchForm_2\"]').click()\n",
    "\n",
    "        # select display criteria\n",
    "        browser.find_element_by_xpath('//*[@id=\"timeSelect\"]/option[contains(text(), \"Display in Square Metre\")]').click()\n",
    "        \n",
    "        time.sleep(10)\n",
    "        browser.implicitly_wait(20)\n",
    "        \n",
    "        #download the file \n",
    "        browser.find_element_by_xpath('//*[@id=\"SubmitSortForm\"]/div[2]/div[3]/input').click()\n",
    "        \n",
    "        time.sleep(5)\n",
    "        browser.implicitly_wait(20)\n",
    "\n",
    "        #go back to previous page\n",
    "        browser.find_element_by_xpath('//*[@id=\"SubmitSortForm\"]/div[2]/div[4]/input').click()\n",
    "\n",
    "        # search by postal district\n",
    "        browser.find_element_by_xpath('//*[@id=\"searchForm\"]/ul/li[2]/a').click()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
