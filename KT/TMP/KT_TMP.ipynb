{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Choose thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(_df, _classifier, _features_columns):\n",
    "    # cross validation type can be changed here\n",
    "    kf = KFold(len(_df), n_folds=3, shuffle=True)\n",
    "    target='target'\n",
    "    prob_of = 'prob_of_all'\n",
    "    \n",
    "    results_cv_targeting = pd.DataFrame([], columns=['masking', target, 'fold', prob_of])\n",
    "\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    mean_lift = []\n",
    "    mean_tp = 0.0\n",
    "    mean_fp = range(0, 101)\n",
    "\n",
    "    nb_calls_cv = pd.DataFrame([],columns=['nb_contacts', 'total_population', 'total_pos_targets', 'nb_pos_targets', 'pos_rate', \n",
    "                                           'Percentage_of_pos_targets_found', 'Percentage_of_Population', 'Lift'])\n",
    "    feature_importances = pd.DataFrame([], columns=['feature', 'importance', 'fold'])\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 12))\n",
    "    fig.subplots_adjust(bottom=-0.5, left=-0.5, top=0.5, right=1.5)\n",
    "\n",
    "    X = _df[np.concatenate([_features_columns,[target]])]\n",
    "    y = _df[target]\n",
    "    \n",
    "    print ('modeling started')\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf):\n",
    "        \n",
    "        train_X, valid_X = X.iloc[train_index], X.iloc[valid_index]\n",
    "        train_Y, valid_Y = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        temp = valid_X[['masking', target]].copy()\n",
    "        temp['fold'] = i\n",
    "\n",
    "        # modeling#\n",
    "        train_X = train_X.drop(['masking', target], axis=1)\n",
    "        valid_X = valid_X.drop(['masking', target], axis=1)\n",
    "\n",
    "        train_Y = np.array(train_Y.astype(np.uint8))\n",
    "        valid_Y = np.array(valid_Y.astype(np.uint8))\n",
    "        \n",
    "\n",
    "\n",
    "        probas_ = _classifier.fit(train_X, train_Y).predict_proba(valid_X)\n",
    "        probabilities = pd.DataFrame(data=probas_[:, 1], index=valid_X.index, columns=[prob_of])\n",
    "\n",
    "        temp = temp.join(probabilities, how='left')\n",
    "        results_cv_targeting = results_cv_targeting.append(temp)\n",
    "\n",
    "        ###############################################################################\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = sk.metrics.roc_curve(valid_Y, probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = sk.metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(fpr, tpr, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        ###############################################################################\n",
    "        # compute lift at 10%#\n",
    "        sorted_proba = np.array(list(reversed(np.argsort(probas_[:, 1]))))\n",
    "        X_test = valid_X\n",
    "        y_test = valid_Y\n",
    "        centile = X_test.shape[0] / 100\n",
    "        positives = sum(y_test)\n",
    "        lift = [0]\n",
    "        for q in xrange(1, 101):\n",
    "            if q == 100:\n",
    "                tp = sum(np.array(y_test)[sorted_proba[(q - 1) * X_test.shape[0] / 100:X_test.shape[0]]])\n",
    "            else:\n",
    "                tp = sum(\n",
    "                    np.array(y_test)[sorted_proba[(q - 1) * X_test.shape[0] / 100:q * X_test.shape[0] / 100]])\n",
    "            lift.append(lift[q - 1] + 100 * tp / float(positives))\n",
    "        quantiles = range(0, 101)\n",
    "        mean_tp += interp(mean_fp, mean_fp, lift)\n",
    "        mean_tp[0] = 0.0\n",
    "        mean_lift.append(lift[10] / 10.)\n",
    "\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(quantiles, lift, label='Lift fold %d at 10 = %0.2f' % (i, lift[10] / 10.))\n",
    "        print ('shuffle: %i, AUC: %f, lift at 10 percent: %f' % (i, roc_auc, lift[10] / 10.))\n",
    "        \n",
    "        ###############################################################################\n",
    "        # Calculate nb contacts to make\n",
    "        nb_calls = temp[['target','prob_of_all','fold']].copy()\n",
    "        nb_calls = nb_calls.sort_values(by='prob_of_all', ascending=False).reset_index(drop=True)\n",
    "        nb_calls['cum_Xsellers'] = np.cumsum(nb_calls.target)\n",
    "        nb_calls = nb_calls.reset_index(drop=False)\n",
    "        nb_calls = nb_calls.rename(columns={'index':'rank'})\n",
    "        nb_calls['nb_contacts_100'] = nb_calls.loc[nb_calls.cum_Xsellers==100,'rank'].min()\n",
    "        nb_calls['nb_contacts_200'] = nb_calls.loc[nb_calls.cum_Xsellers==200,'rank'].min()\n",
    "        nb_calls['nb_contacts_500'] = nb_calls.loc[nb_calls.cum_Xsellers==500,'rank'].min()\n",
    "        nb_calls['nb_contacts_1000'] = nb_calls.loc[nb_calls.cum_Xsellers==1000,'rank'].min()\n",
    "        nb_calls['nb_contacts_2000'] = nb_calls.loc[nb_calls.cum_Xsellers==2000,'rank'].min()\n",
    "        nb_calls['nb_contacts_3000'] = nb_calls.loc[nb_calls.cum_Xsellers==3000,'rank'].min()\n",
    "        nb_calls['nb_contacts_all'] = nb_calls.loc[nb_calls.cum_Xsellers==nb_calls.cum_Xsellers.max(),'rank'].min()\n",
    "        nb_calls = nb_calls[['nb_contacts_100','nb_contacts_200', 'nb_contacts_500','nb_contacts_1000', 'nb_contacts_2000','nb_contacts_3000','nb_contacts_all']].min()\n",
    "        nb_calls = pd.DataFrame(nb_calls,columns=['nb_contacts'])\n",
    "        nb_calls['total_population'] = temp.shape[0]\n",
    "        nb_calls['total_pos_targets'] = temp.target.sum()\n",
    "        nb_calls['nb_pos_targets']=[100,200,500,1000,2000,3000, temp.target.sum()]\n",
    "        nb_calls['pos_rate'] = nb_calls.nb_pos_targets/nb_calls.nb_contacts\n",
    "        nb_calls['Percentage_of_pos_targets_found'] = nb_calls.nb_pos_targets/nb_calls.total_pos_targets\n",
    "        nb_calls['Percentage_of_Population'] = nb_calls.nb_contacts/nb_calls.total_population\n",
    "        nb_calls['Lift'] = nb_calls.Percentage_of_pos_targets_found/nb_calls.Percentage_of_Population\n",
    "\n",
    "        nb_calls_cv = nb_calls_cv.append(nb_calls)\n",
    "        \n",
    "        ###############################################################################\n",
    "        feature_importances_data = []\n",
    "        features = train_X.columns\n",
    "        for feature_name, feature_importance in get_importance(_classifier.booster(), 'gain').iteritems():\n",
    "            feature_importances_data.append({\n",
    "                'feature': feature_name,\n",
    "                'importance': feature_importance\n",
    "            })\n",
    "\n",
    "        temp = pd.DataFrame(feature_importances_data)\n",
    "        temp['fold'] = i\n",
    "        feature_importances = feature_importances.append(temp)\n",
    "    \n",
    "    nb_calls_cv = nb_calls_cv.reset_index().groupby('index').mean().sort_values(by='nb_pos_targets')\n",
    "    nb_calls_cv['total_population'] = nb_calls_cv['total_population'].apply(lambda x : round(x,0))\n",
    "    results_cv_targeting = results_cv_targeting.reset_index(drop=True)\n",
    "    \n",
    "    feature_importances = feature_importances.groupby('feature')['importance'].agg([np.mean, np.std])\n",
    "    feature_importances = feature_importances.sort_values(by='mean')\n",
    "    feature_importances = feature_importances.reset_index()\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    mean_tpr /= len(kf)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = sk.metrics.auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    mean_tp /= len(kf)\n",
    "    mean_tp[-1] = 100.0\n",
    "    mean_lift10 = np.mean(mean_lift)\n",
    "    print('Mean AUC: %f, Mean lift at 10 percent: %f' % (mean_auc, mean_lift10))\n",
    "    plt.plot(mean_fp, mean_tp, 'k--', label='Mean lift at 10 = %0.2f' % mean_lift10, lw=2)\n",
    "\n",
    "    plt.plot([0, 100], [0, 100], 'k--', color=(0.6, 0.6, 0.6))\n",
    "    plt.xlim([-5, 105])\n",
    "    plt.ylim([-5, 105])\n",
    "    plt.xlabel('Percentage of population')\n",
    "    plt.ylabel('Cumulative gain')\n",
    "    plt.title('Lift', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return results_cv_targeting, feature_importances, nb_calls_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters of the classifier need to be changed according to datasets\n",
    "classifier = xgb.XGBClassifier(objective='binary:logistic',max_depth=6,n_estimators=200, learning_rate=0.05,max_delta_step=1,\n",
    "                        min_child_weight=25, gamma=0.1, scale_pos_weight=1, colsample_bytree=0.85, subsample=0.85,colsample_bylevel=0.85,\n",
    "                        nthread=10, seed=27)\n",
    "\n",
    "results_cv_targeting, feature_importances, nb_calls_cv = run_cross_validation(dataset_modelA_clean_targeting, classifier , feature_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_calls_all_cv = pd.DataFrame([],columns=['nb_contacts', 'total_population', 'total_pos_targets', 'nb_pos_targets', 'pos_rate', \n",
    "                                           'Percentage_of_pos_targets_found', 'Percentage_of_Population', 'Lift'])\n",
    "\n",
    "# Calculate nb calls to make\n",
    "nb_calls_all = results_cv_targeting[['target', 'prob_of_all']].copy()\n",
    "nb_calls_all = nb_calls_all.sort_values(by='prob_of_all', ascending=False).reset_index(drop=True)\n",
    "nb_calls_all['cum_Xsellers'] = np.cumsum(nb_calls_all.target)\n",
    "nb_calls_all = nb_calls_all.reset_index(drop=False)\n",
    "nb_calls_all = nb_calls_all.rename(columns={'index': 'rank'})\n",
    "nb_calls_all['nb_calls_100'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 100, 'rank'].min()\n",
    "nb_calls_all['nb_calls_200'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 200, 'rank'].min()\n",
    "nb_calls_all['nb_calls_500'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 500, 'rank'].min()\n",
    "nb_calls_all['nb_calls_1000'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 1000, 'rank'].min()\n",
    "nb_calls_all['nb_calls_2000'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 2000, 'rank'].min()\n",
    "nb_calls_all['nb_calls_3000'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == 3000, 'rank'].min()\n",
    "nb_calls_all['nb_calls_all'] = nb_calls_all.loc[nb_calls_all.cum_Xsellers == nb_calls_all.cum_Xsellers.max(), 'rank'].min()\n",
    "nb_calls_all = nb_calls_all[\n",
    "    ['nb_calls_100', 'nb_calls_200', 'nb_calls_500', 'nb_calls_1000', 'nb_calls_2000', 'nb_calls_3000',\n",
    "     'nb_calls_all']].min()\n",
    "nb_calls_all = pd.DataFrame(nb_calls_all, columns=['nb_contacts'])\n",
    "nb_calls_all['total_population'] = results_cv_targeting.shape[0]\n",
    "nb_calls_all['total_pos_targets'] = results_cv_targeting.target.sum()\n",
    "nb_calls_all['nb_pos_targets']=[100,200,500,1000,2000,3000, results_cv_targeting.target.sum()]\n",
    "nb_calls_all['pos_rate'] = nb_calls_all.nb_pos_targets/nb_calls_all.nb_contacts\n",
    "nb_calls_all['Percentage_of_pos_targets_found'] = nb_calls_all.nb_pos_targets/nb_calls_all.total_pos_targets\n",
    "nb_calls_all['Percentage_of_Population'] = nb_calls_all.nb_contacts/nb_calls_all.total_population\n",
    "nb_calls_all['Lift'] = nb_calls_all.Percentage_of_pos_targets_found/nb_calls_all.Percentage_of_Population\n",
    "\n",
    "\n",
    "nb_calls_all_cv = nb_calls_all_cv.append(nb_calls_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##objective for having 500 positive targets\n",
    "\n",
    "p1 = results_cv_targeting.sort_values(by='prob_of_all',ascending=False).reset_index(drop=True)\n",
    "p1['nb_pos_target']=np.cumsum(p1.target)\n",
    "index = p1.loc[p1.nb_pos_target==500].index.min()\n",
    "print('min number to contact %f to get 500 Xsellers'%(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##objective for taking maximum of agents capability (1/10 per week, min conversion rate 10%)\n",
    "\n",
    "r1 = results_cv_targeting.sort_values(by='prob_of_all',ascending=False).reset_index(drop=True)\n",
    "r1['nb_pos_target'] = np.cumsum(r1.target)\n",
    "r1 = r1.reset_index(drop=False)\n",
    "r1 = r1.rename(columns={'index':'nb_contact'})\n",
    "r1.nb_contact = r1.nb_contact+1\n",
    "r1['pos_rate'] = r1['nb_pos_target'] / r1['nb_contact']\n",
    "index = r1[(r1.pos_rate>0.1)].index.max()\n",
    "print('max nb to contact %f customers to guarantee 10percente conversion rate'%(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
